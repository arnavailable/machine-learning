{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8A0yIDCtJLa"
   },
   "source": [
    "# Homework 1 - Linear Regression\n",
    "\n",
    "## Dataset\n",
    "The dataset you will be using is about Life expectancy of different countries. We will explore how immunization factors, mortality factors, economic factors, social factors and other health related factors affect Life expectancy of a country.\n",
    "\n",
    "There are two data files: \"LifeExpectancy_training_modified.csv\" and \"LifeExpectancy_test_modified.csv\"<br/>\n",
    "Both files have the following fields, except Life_expectancy which is not available in \"LifeExpectancy_test_modified.csv\"\n",
    "\n",
    "Features :\n",
    "- Year : from 2002 to 2015\n",
    "- Status : Developed or Developing status\n",
    "- Adult_Mortality : Adult Mortality Rates of both sexes (probability of dying between 15 and 60 years per 1000 population)\n",
    "- Alcohol : Alcohol, recorded per capita (15+) consumption (in litres of pure alcohol)\n",
    "- percentage_expenditure : Expenditure on health as a percentage of Gross Domestic Product per capita(%)\n",
    "- BMI: Average Body Mass Index of entire population\n",
    "- Total_expenditure: General government expenditure on health as a percentage of total government expenditure (%)\n",
    "- Diphtheria: Diphtheria tetanus toxoid and pertussis (DTP3) immunization coverage among 1-year-olds (%)\n",
    "- HIV_AIDS: Deaths per 1000 live births HIV/AIDS (0-4 years)\n",
    "- GDP: Gross Domestic Product per capita (in USD)\n",
    "- Population\n",
    "- Income_composition_of_resources: Human Development Index in terms of income composition of resources (index ranging from 0 to 1)\n",
    "- Schooling: Number of years of Schooling(years)\n",
    "- Health_Index: Health index \n",
    "\n",
    "Target:\n",
    "- Life_expectancy: Life Expectancy in age\n",
    "\n",
    "\n",
    "Training dataset, \"LifeExpectancy_training_modified.csv\", contains 1064 rows and 15 columns. This is the training set containing both of the features and the target.<br/>\n",
    "Test dataset, \"LifeExpectancy_test_modified.csv\", contains 458 rows and 14 columns. This is the test set which only contains the features.<br/>\n",
    "\n",
    "Your goal is to predict Life expectancy based on the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xwWTXsa30LLu"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JGLaGzbL0jdH"
   },
   "source": [
    "Load the training data \"LifeExpectancy_training_modified.csv\" in Colab and View the first 5 lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u5oaCEzI0se8"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "viQgJ6uy03nd"
   },
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "import io\n",
    "df = pd.read_csv(io.BytesIO(uploaded['LifeExpectancy_training_modified.csv']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bTxYGeoSxcKs"
   },
   "outputs": [],
   "source": [
    "# Show the first 5 lines\n",
    "### WRITE CODE ###\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kIRo3Da91IdF"
   },
   "source": [
    "## Data Exploration\n",
    "We can plot a histogram of the dataframe for the features except \"Status\" to understand their distributions. <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iemQk82B3Nam"
   },
   "outputs": [],
   "source": [
    "### WRITE CODE TO OBTAIN AND DISPLAY HISTOGRAMS ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_XD0AGPM5eaD"
   },
   "source": [
    "##### Q1. What can you infer from the histograms? <br/>\n",
    "Ans-\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xmq41MOV9Z8d"
   },
   "source": [
    "Compute the correlation matrix to get an understanding of the correlation between life_expectancy and the other features.<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WmuZTzx29bkO"
   },
   "outputs": [],
   "source": [
    "### WRITE CODE TO OBTAIN CORRELATION MATRIX ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8UpsTJyw97FZ"
   },
   "source": [
    "##### Answer the following questions:<br/>\n",
    "\n",
    "##### Q2. Why is the diagonal made up of 1's in the correlation matrix?<br/>\n",
    "Ans-\n",
    "\n",
    "##### Q3. Why is the matrix symmetric along diagonal?<br/>\n",
    "Ans-\n",
    "\n",
    "##### Q4. Looking at the correlation matrix, if you have to choose one predictor for a simple linear regression model with Life_expectancy as the outcome, which one would you choose and why? <br/>\n",
    "Ans-\n",
    "\n",
    "##### Q4.1. Is there any variable that does not make sense to you and why? <br/>\n",
    "Ans-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYvGzY8Z-ni-"
   },
   "source": [
    "### Standardization of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jhq-T3Ed-r8w"
   },
   "source": [
    "Feature standardization makes the values of each feature in the data have zero-mean and unit-variance. This method is widely used for normalization in many machine learning algorithms. The general method of calculation is to determine the distribution mean and standard deviation for each feature. Next we subtract the mean from each feature. Then we divide the values of each feature by its standard deviation.\n",
    "\n",
    "$x'$ = ($x$ - $\\bar{x}$)/$\\sigma$ \n",
    "\n",
    "where $x$ is the original feature vector,\n",
    "$\\bar{x}$ is the mean of the feature vector and\n",
    "$\\sigma$ is its standard deviation.\n",
    "\n",
    "This is also called Z-score Normalization. \n",
    "\n",
    "Perform Z-score Normalization on the features (except \"Year\" and \"Status\") in both training and test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iD2UmlarDHY_"
   },
   "outputs": [],
   "source": [
    "# Load the test set \"LifeExpectancy_test_modified.csv\"\n",
    "### WRITE CODE ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a8Hu-t4eBphh"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "### WRITE CODE TO PERFORM Z-score Normalization ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zwfacAsAFBbs"
   },
   "source": [
    "##### Q5. What are the advantages and disadvantages of using Z-score Normalization?<br/>\n",
    "Ans-  \n",
    "\n",
    "##### Q6. In this dataset, do you need to use the Z-score Normalization? Explain.<br/>\n",
    "Ans- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5tr1XcvyFIcN"
   },
   "source": [
    "### One-Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fyyGwM3JFS4Y"
   },
   "source": [
    "\"Year\" and \"Status\" can only take discrete values. We need to perform one-hot encoding on discrete values for it to be processed in the model. One hot encoding is a process by which categorical variables are converted into a form that could be provided to ML algorithms to do a better job in prediction.\n",
    "Perform one-hot encoding on \"Year\" and \"Status\" and print the shape of your encoded array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CVbI2IVxFuHn"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "### WRITE CODE TO PERFORM ONE-HOT CODING ON \"Year\" AND \"Status\" ###\n",
    "\n",
    "\n",
    "# Print the shape of your encoded X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IvbDqp5bJ-Xx"
   },
   "source": [
    "Q7. What are the other types of encodings and why did we use One-hot encoding for \"Year\" and \"Status\"?\n",
    "\n",
    "Ans- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fp5S0WizKI0g"
   },
   "source": [
    "## Multiple Linear Regression\n",
    "\n",
    "In the big data era, it is highly unlikely that we are interested in the effect of a single variable on another. To simultaneously account for the effects of multiple variables, we use multiple regression (which accounts for the covariances between predictors).\n",
    "\n",
    "While the algorithmic solution to multiple regression exists, it is easier to conceptualize in terms of linear algebra. The optimal $\\hat{\\beta}$ vector that minimizes the residual sum of squares is:\n",
    "\n",
    "$\\hat{\\beta} = (X^TX)^{-1}X^Ty $\n",
    "\n",
    "\n",
    "Perform multiple linear regression on the training dataset, where the outcome is \"Life_expectancy\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3-saM1rTKjKH"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GTfbR3b-KoeW"
   },
   "outputs": [],
   "source": [
    "### Bulding and fitting the Multiple Linear Regression model###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FpQe-p3LLXgA"
   },
   "outputs": [],
   "source": [
    "### Evaluate the Linear Regression model by computing MSE on the training set###\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O2jOEvNiO84E"
   },
   "source": [
    "Q8. Print the value of coefficients and also the corresponding variable names for the coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q18iLjtHX25r"
   },
   "source": [
    "Q9. Is there a problem of multicolinearity? Explain what you can do\n",
    "\n",
    "Ans-  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJ51d6d2YyPp"
   },
   "source": [
    "### Goodness of fit\n",
    "\n",
    "A model can always make predictions. But it is important to determine how good the model is.\n",
    "How do we know that our model captures the data well? When evaluating model fit, a good metric is $R^2$, which corresponds to the amount of variance explained by the model. The formula for $R^2$ is the following:\n",
    "\n",
    "$R^2$ = $1 - \\dfrac{RSS}{TSS}$<br/>\n",
    "where:<br/>\n",
    "$RSS = \\Sigma(y - \\hat{y})^2$<br/>\n",
    "$TSS = \\Sigma(y - \\bar{y})^2$<br/>\n",
    "\n",
    "$R^2$ is also one metric for comparing models against each other. It is intuitive to say that the model that explains more variation in the data is a better fit than one that explains less variation. \n",
    "\n",
    "Fill in the code for calculation of R2 score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hr0giuHXY4J5"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kFiC_mfgY7m1"
   },
   "source": [
    "$R^2$ for model with \"Schooling\" as predictor and \"Life_expectancy\" as outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LIspp_FPaicb"
   },
   "outputs": [],
   "source": [
    "### WRITE CODE ###\n",
    "\n",
    "# Print R2 score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5fGTnWcobCc_"
   },
   "source": [
    "$R^2$ for model with \"Schooling\", \"Adult_Mortality\" as predictor and \"Life_expectancy\" as outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XqBXqRZlbjy7"
   },
   "outputs": [],
   "source": [
    "### WRITE CODE ###\n",
    "\n",
    "# Print R2 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dE1PDtR0bVdX"
   },
   "source": [
    "$R^2$ for model with \"Schooling\",\"Adult_Mortality\" and \"Population\" as predictor and \"Life_expectancy\" as outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5WxDGrKqbyR2"
   },
   "outputs": [],
   "source": [
    "### WRITE CODE ###\n",
    "\n",
    "# Print R2 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vYdvN1CTcMuN"
   },
   "source": [
    "You can see $R^2$ is always going up as we keep adding features.\n",
    "\n",
    "This is one drawback of only using $R^2$ to evaluate your model. Adding predictors seems to always improve the predictive ability of your model, though it may not be true.\n",
    "\n",
    "That is to say, we are not necessarily interested in making a perfect prediciton of our training data. If we were, we would always use all of the predictors available. Rather, we would like to make a perfect prediction of our test data. In this case, adding all the predictors may not be a good idea due to the trade-off between bias and variance. Thus, we are interested in the most predictive features, in the hopes that we can create a simpler model that performs well in the future.\n",
    "\n",
    "This is why we consider another metric, Adjusted R2.\n",
    "The adjusted R-squared increases only if the new term improves the model more than would be expected by chance.\n",
    "\n",
    "\n",
    "$AdjustedR^2$ = $1 - \\dfrac{(1-R^2)(n-1)}{(n-p-1)}$<br/>\n",
    "where:<br/>\n",
    "n = number of samples<br/>\n",
    "p = number of features\n",
    "\n",
    "Fill in the code for calculation of adjusted R2 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CCqEwoDNcOgb"
   },
   "source": [
    "Adjusted $R^2$ for model with \"Schooling\" as predictor and \"Life_expectancy\" as outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mCgTtpskch0n"
   },
   "outputs": [],
   "source": [
    "### WRITE CODE ###\n",
    "\n",
    "# Print Adjusted R2 score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKLKf_ODc842"
   },
   "source": [
    "Adjusted $R^2$ for model with \"Schooling\", \"Adult_Mortality\" as predictor and \"Life_expectancy\" as outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n6j0eaIxdFoD"
   },
   "outputs": [],
   "source": [
    "### WRITE CODE ###\n",
    "\n",
    "# Print Adjusted R2 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R3oT1NbDdRcK"
   },
   "source": [
    "Adjusted $R^2$ for model with \"Schooling\",\"Adult_Mortality\" and \"Population\" as predictor and \"Life_expectancy\" as outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KLOFJL2LdVEz"
   },
   "outputs": [],
   "source": [
    "### WRITE CODE ###\n",
    "\n",
    "# Print Adjusted R2 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDHU67n8d4x7"
   },
   "source": [
    "### K-fold Cross-Validation\n",
    "\n",
    "However, adjusted $R^2$ is not enough to help us ahieve the best model, a more robust method is k-fold cross-validation.\n",
    "\n",
    "* Randomly split dataset into K equal-sized subsets, or folds\n",
    "* Treat each fold as validation set (train on all but K'th fold and test on K'th fold only)\n",
    "\n",
    "* The overall error is then the mean error over all K models.\n",
    "* Most common are 5- or 10-fold cross-validation\n",
    "\n",
    "Please implement a 5-fold cross-validation by yourselves to find the best model in terms of Mean Square Error(MSE)\n",
    "\n",
    "**Do not use sklearn.model_selection.cross_val_score or other built-in cross-validaiton functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QnbM2CcZFhWs"
   },
   "outputs": [],
   "source": [
    "# Design a function to implement 5-fold cross-validation. \n",
    "# The input: training features X, training target y and # of folds f=5.\n",
    "# The output: the average of MSE over the 5 folds.\n",
    "\n",
    "def cross_val_mse(X, y, f):\n",
    "    ### Write your code here ###\n",
    "    \n",
    "\n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZxURVCdbFuWB"
   },
   "outputs": [],
   "source": [
    "# By using your above functions, find the best combination of features, which has the lowest averaged MSE \n",
    "from itertools import combinations \n",
    "### Write code here ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T3WWuFZ-eGGE"
   },
   "outputs": [],
   "source": [
    "# Print the best features and the corresponding mse\n",
    "### WRITE CODE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-WBDncGtiY2"
   },
   "source": [
    "### Test your model\n",
    "Now, apply your best model to predict the target values from the test feature set \"LifeExpectancy_test_modified.csv\". We will grade this part based on your prediction error.\n",
    "\n",
    "Hint: Please be careful on standardization and one-hot encoding (if you use), the test set should be consistent with the training set in terms of any transformation.\n",
    "\n",
    "Hint2: You may want to modify the previous steps to make the transformation of the test set consistent with the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tYJ-KOqzuLj2"
   },
   "outputs": [],
   "source": [
    "### WRITE CODE ###\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YAUlAuc09Uk9"
   },
   "outputs": [],
   "source": [
    "# Output your prediction on test set as y_pred.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aPfqPkQ2vbq7"
   },
   "outputs": [],
   "source": [
    "#end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual student contribution \n",
    "Student 1 name - contribution (ex- Q 1,2,3) </br>\n",
    "Student 2 name - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MSA_401_Exercise_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
